# Data-Transformation-Pipelines using spark
## notebook steps
a) uploaded data files to a DBFS table space

b) To load data and use it, used spark scala to load data into an RDD

c) Count the occurrence of two words “patient” and “admitted” on the same line of text using transformation functions in a pipeline.
